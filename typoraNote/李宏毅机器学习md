## 课程信息

课程地址：https://speech.ee.ntu.edu.tw/~hylee/ml/2022-spring.php

CSDN: https://blog.csdn.net/zzh516451964zzh/article/details/123212671

## 这个可以理解为，训练了编码器，也可以叫特征提取器

### label：正确的数值

MSE（均方误差）、RMSE （均方根误差）、MAE （平均绝对误差）

cross-entropy = 交叉熵 损失函数

微分就是计算导数

无论拐点还是驻点，其斜率均为0，因此目标点附近斜率很小，因此斜率越小步伐越小

hyperparameters：机器学习中需要自己设定的东西

因为偏导数总是指往函数相上的方向，想要使得loss更低，就往反方向走就可以了，所以是减号

因为梯度（导数）是函数增长最快的方向，所以取负（反方向）

gradient disappear  local minima

因为维度太多，所以基本都是鞍点，真正的local minima基本遇不到

梯度消失和梯度爆炸

这里的计算一定要simultaneously



梯度垂直于等高线，指向低位置

gradient descent



domain knowledge

过拟合是迭代次数过多

因为增加参数，会减少残差，但总的离差不会变